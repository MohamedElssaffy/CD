version: 2.1
workflows:
  CreateInfra:
    jobs:
      - create_and_deploy_front_end
      - promote_to_production:
          requires:
            - create_and_deploy_front_end
      - get_last_deployment_id
      - clean_up_old_front_end:
          requires:
            - get_last_deployment_id
            - promote_to_production
      # - createInfra
      #   - configure_infra:
      #       requires: [createInfra]
      # - smoke_test:
      #     requires: [configure_infra]
      # - fail_job:
      #     requires: [createInfra]

commands:
  destroy_environments:
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}

jobs:
  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Create a s3 bucket
          command: |
            aws cloudformation deploy \
            --template-file bucket.yml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
            --parameter-overrides MyBucketName='mybucket-${CIRCLE_WORKFLOW_ID:0:7}'
      - run:
          name: upload file to s3 bucket
          command: |
            aws s3  cp ./index.html s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7}
  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - textfile.txt
  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yml
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yml \
            --stack-name production-distro \
            --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous S3 bucket and CloudFormation stack.
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro
          command: |
            export OldBucketID=$(cat ~/textfile.txt)
            aws s3 rm "s3://${OldBucketID}" --recursive

  # Exercise Create Infrastructure
  # createInfra:
  #   docker:
  #     - image: amazon/aws-cli
  #   steps:
  #     - checkout
  #     - run:
  #         name: Create Cloudformation Stack
  #         command: |
  #           aws cloudformation create-stack \
  #           --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
  #           --template-body file://infr.yml \
  #           --parameters file://infr-params.json
  # Exercise Create configure for server
  #   configure_infra:
  #     docker:
  #       - image: python:3.7-alpine3.11
  #     steps:
  #       - checkout
  #       - add_ssh_keys:
  #           fingerprints: ['e7:f6:73:c6:2b:61:43:c2:4b:60:14:b3:9b:5a:ff:89']
  #       - run:
  #           name: install aws cli
  #           command: pip3 install awscli
  #       - run:
  #           name: create .aws folder
  #           command: mkdir ~/.aws
  #       - run:
  #           name: add credential for aws connect
  #           command: echo '[default]\aws_access_key_id=$AWS_ACCESS_KEY_ID\aws_secret_access_key=$AWS_SECRET_ACCESS_KEY' > ~/.aws/credentials

  #       - run:
  #           name: add config for aws
  #           command: echo '[default]\region = $AWS_DEFAULT_REGION\output=json' > ~/.aws/config
  #       - run:
  #           name: create inventory file
  #           command: echo '[all]'> inventory.txt
  #       - run:
  #           name: add ip address in inventory from aws
  #           command: aws ec2 describe-instances --query 'Reservations[*].Instances[*].PublicIpAddress' --output text >> inventory.txt
  #       - run: aws ec2 describe-instances --query 'Reservations[*].Instances[*].PublicIpAddress' --output text
  #       - run:
  #           name: install ansible
  #           command: apk add --update ansible
  #       - run:
  #           name: run playbook and configure server
  #           command: ansible-playbook -i inventory.txt playbook.yml
  # Exercise: Smoke Testing
  # smoke_test:
  #   docker:
  #     - image: alpine:latest
  #   steps:
  #     - run: apk add --update curl
  #     - run:
  #         name: smoke test
  #         command: |
  #           URL="https://blog.udacity.com/"
  #           if curl -s --head ${URL}
  #           then
  #           return 0
  #           else
  #           return 1
  #           fi
  # fail_job:
  #   docker:
  #     - image: amazon/aws-cli
  #   steps:
  #     - run: return 1
  #     - destroy_environments
